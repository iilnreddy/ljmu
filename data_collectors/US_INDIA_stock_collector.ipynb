{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f418a5ec-a5f5-4545-b06d-f853ef9ab58f",
   "metadata": {},
   "source": [
    "# Key Features\n",
    "#### Dynamic NIFTY CSV parsing → avoids ParserError.\n",
    "#### Dow Jones handled separately via Wikipedia API.\n",
    "#### Multi-index tagging → symbols in multiple indices are combined with |.\n",
    "#### Deduplication → keeps one row per (Stock Symbol, Stock Market).\n",
    "#### Simple, maintainable structure — easy to extend for ISIN, sector, country later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accb5d0-c0ae-4a30-9862-6120fe355349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading S&P500 (attempt 1)\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\S&P500.csv\n",
      "Downloading NASDAQ (attempt 1)\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\NASDAQ.csv\n",
      "Downloading NYSE (attempt 1)\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\NYSE.csv\n",
      "Downloading NIFTY50 (attempt 1)\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\NIFTY50.csv\n",
      "Downloading NIFTY500 (attempt 1)\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\NIFTY500.csv\n",
      "Downloading DOW_JONES from Wikipedia API\n",
      "✅ Saved raw file → ..\\Data\\raw_csv\\DOW_JONES.csv\n",
      "⬇️ Downloading DOW_JONES from Wikipedia API\n",
      "✅ Saved DOW_JONES → ..\\Data\\raw_csv\\DOW_JONES.csv\n",
      "✅ Normalized file created → ..\\Data\\normalized_csv\\ALL_INDEX_STOCKS.csv\n",
      "Total rows: 9104\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Directories\n",
    "# =========================\n",
    "RAW_DIR = Path(\"../Data/raw_csv\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# Index URLs\n",
    "# =========================\n",
    "URLS = {\n",
    "    # US (DataHub)\n",
    "    \"S&P500\": \"https://datahub.io/core/s-and-p-500-companies/r/constituents.csv\",\n",
    "    \"NASDAQ\": \"https://datahub.io/core/nasdaq-listings/r/nasdaq-listed-symbols.csv\",\n",
    "    \"NYSE\": \"https://datahub.io/core/nyse-other-listings/_r/-/data/nyse-listed.csv\",\n",
    "    # INDIA (NIFTY)\n",
    "    \"NIFTY50\": \"https://www.niftyindices.com/IndexConstituent/ind_nifty50list.csv\",\n",
    "    \"NIFTY500\": \"https://www.niftyindices.com/IndexConstituent/ind_nifty500list.csv\",\n",
    "}\n",
    "\n",
    "# Browser-like headers (CRITICAL for NIFTY)\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/csv,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Referer\": \"https://www.niftyindices.com/\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Download with retries\n",
    "# =========================\n",
    "def download_with_retry(session, name, url, retries=3):\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            print(f\"Downloading {name} (attempt {attempt})\")\n",
    "            resp = session.get(url, headers=HEADERS, timeout=120)\n",
    "            resp.raise_for_status()\n",
    "            return resp.content\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Attempt {attempt} failed for {name}: {e}\")\n",
    "            sleep(5 * attempt)\n",
    "    raise RuntimeError(f\"❌ Failed after {retries} attempts: {name}\")\n",
    "\n",
    "# =========================\n",
    "# Download all raw CSVs\n",
    "# =========================\n",
    "def download_raw():\n",
    "    with requests.Session() as session:\n",
    "        for name, url in URLS.items():\n",
    "            content = download_with_retry(session, name, url)\n",
    "            file_path = RAW_DIR / f\"{name}.csv\"\n",
    "            file_path.write_bytes(content)\n",
    "            print(f\"✅ Saved raw file → {file_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Dow Jones (Wikipedia)\n",
    "        # -------------------------\n",
    "        print(\"Downloading DOW_JONES from Wikipedia API\")\n",
    "        WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "        params = {\"action\": \"parse\", \"page\": \"Dow_Jones_Industrial_Average\",\n",
    "                  \"prop\": \"text\", \"format\": \"json\"}\n",
    "        r = session.get(WIKI_API, params=params, headers={\"User-Agent\": \"IndexDataCollector/1.0\"}, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        html = r.json()[\"parse\"][\"text\"][\"*\"]\n",
    "        tables = pd.read_html(StringIO(html))\n",
    "        djia_table = next(t for t in tables if {\"Company\", \"Symbol\"}.issubset(set(t.columns)))\n",
    "        djia_df = djia_table[[\"Company\", \"Symbol\"]]\n",
    "        djia_df.columns = [\"Stock Name\", \"Stock Symbol\"]\n",
    "        djia_path = RAW_DIR / \"DOW_JONES.csv\"\n",
    "        djia_df.to_csv(djia_path, index=False)\n",
    "        print(f\"✅ Saved raw file → {djia_path}\")\n",
    "\n",
    " \n",
    "\n",
    "# =========================\n",
    "# Download Dow Jones via Wikipedia\n",
    "# =========================\n",
    "def download_dow_jones():\n",
    "    print(\"⬇️ Downloading DOW_JONES from Wikipedia API\")\n",
    "    WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "    headers = {\"User-Agent\": \"IndexDataCollector/1.0\"}\n",
    "    params = {\"action\": \"parse\", \"page\": \"Dow_Jones_Industrial_Average\",\n",
    "              \"prop\": \"text\", \"format\": \"json\"}\n",
    "    r = requests.get(WIKI_API, params=params, headers=headers, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    html = r.json()[\"parse\"][\"text\"][\"*\"]\n",
    "    tables = pd.read_html(StringIO(html))\n",
    "    djia_table = next(t for t in tables if {\"Company\", \"Symbol\"}.issubset(set(t.columns)))\n",
    "    djia_df = djia_table[[\"Company\", \"Symbol\"]]\n",
    "    djia_df.columns = [\"Stock Name\", \"Stock Symbol\"]\n",
    "    path = RAW_DIR / \"DOW_JONES.csv\"\n",
    "    djia_df.to_csv(path, index=False)\n",
    "    print(f\"✅ Saved DOW_JONES → {path}\")\n",
    "    return djia_df\n",
    "    \n",
    "RAW_DIR = Path(\"../Data/raw_csv\")\n",
    "OUT_DIR = Path(\"../Data/normalized_csv\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# Process Index CSVs\n",
    "# =========================\n",
    "def process_sp500():\n",
    "    df = pd.read_csv(RAW_DIR / \"S&P500.csv\")\n",
    "    return pd.DataFrame({\n",
    "        \"Stock Name\": df[\"Security\"],\n",
    "        \"Stock Symbol\": df[\"Symbol\"],\n",
    "        \"Stock Market\": \"NYSE/NASDAQ\",\n",
    "        \"INDEX\": \"S&P 500\"\n",
    "    })\n",
    "\n",
    "def process_nasdaq():\n",
    "    df = pd.read_csv(RAW_DIR / \"NASDAQ.csv\")\n",
    "    return pd.DataFrame({\n",
    "        \"Stock Name\": df[\"Company Name\"],\n",
    "        \"Stock Symbol\": df[\"Symbol\"],\n",
    "        \"Stock Market\": \"NASDAQ\",\n",
    "        \"INDEX\": \"NASDAQ\"\n",
    "    })\n",
    "\n",
    "def process_nyse():\n",
    "    csv_path = RAW_DIR / \"NYSE.csv\"\n",
    "    if not csv_path.exists():\n",
    "        print(\"⚠️ NYSE.csv not found, skipping NYSE index\")\n",
    "        return pd.DataFrame(columns=[\"Stock Name\",\"Stock Symbol\",\"Stock Market\",\"INDEX\"])\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return pd.DataFrame({\n",
    "        \"Stock Name\": df[\"Company Name\"],\n",
    "        \"Stock Symbol\": df[\"ACT Symbol\"],\n",
    "        \"Stock Market\": \"NYSE\",\n",
    "        \"INDEX\": \"NYSE\"\n",
    "    })\n",
    "\n",
    "def process_nifty(index_name):\n",
    "    csv_path = RAW_DIR / f\"{index_name}.csv\"\n",
    "    if not csv_path.exists():\n",
    "        print(f\"⚠️ {index_name}.csv not found, skipping\")\n",
    "        return pd.DataFrame(columns=[\"Stock Name\",\"Stock Symbol\",\"Stock Market\",\"INDEX\"])\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[[\"Company Name\", \"Symbol\"]]\n",
    "    return pd.DataFrame({\n",
    "        \"Stock Name\": df[\"Company Name\"],\n",
    "        \"Stock Symbol\": df[\"Symbol\"],\n",
    "        \"Stock Market\": \"NSE\",\n",
    "        \"INDEX\": index_name.replace(\"NIFTY\", \"NIFTY \")\n",
    "    })\n",
    "\n",
    "def process_dow_jones():\n",
    "    df = pd.read_csv(RAW_DIR / \"DOW_JONES.csv\")\n",
    "    return pd.DataFrame({\n",
    "        \"Stock Name\": df[\"Stock Name\"],\n",
    "        \"Stock Symbol\": df[\"Stock Symbol\"],\n",
    "        \"Stock Market\": \"NYSE/NASDAQ\",\n",
    "        \"INDEX\": \"DOW JONES\"\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    download_raw()\n",
    "    download_dow_jones()\n",
    "\n",
    "    # Process all indices\n",
    "    datasets = [\n",
    "        process_sp500(),\n",
    "        process_nasdaq(),\n",
    "        process_nyse(),\n",
    "        process_nifty(\"NIFTY50\"),\n",
    "        process_nifty(\"NIFTY500\"),\n",
    "        process_dow_jones(),\n",
    "    ]\n",
    "\n",
    "    # Combine, deduplicate, and aggregate\n",
    "    final_df = pd.concat(datasets, ignore_index=True)\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df = (final_df.groupby([\"Stock Symbol\", \"Stock Market\"], as_index=False)\n",
    "                .agg({\"Stock Name\": \"first\",\n",
    "                      \"INDEX\": lambda x: \"|\".join(sorted(set(x)))}))\n",
    "\n",
    "    out_file = OUT_DIR / \"ALL_INDEX_STOCKS.csv\"\n",
    "    final_df.to_csv(out_file, index=False)\n",
    "\n",
    "    print(f\"✅ Normalized file created → {out_file}\")\n",
    "    print(f\"Total rows: {len(final_df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1f504-f5c3-40f0-ae54-2a982d4245dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
